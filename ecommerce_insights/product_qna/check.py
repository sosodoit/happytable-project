from google.cloud import bigquery
from google.oauth2 import service_account
from datetime import datetime
from pathlib import Path
import argparse

# ì¸ì¦ ë° BQ í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent.parent.parent
CREDENTIALS_FILE = str((BASE_DIR / "manggu-e08c8cf179d0.json").as_posix())
credentials = service_account.Credentials.from_service_account_file(CREDENTIALS_FILE)
client = bigquery.Client(credentials=credentials, project=credentials.project_id)

# í…Œì´ë¸” ì •ë³´
project_id = "manggu"
dataset_id = "ecommerce_insights"
table_id = "product_qna"

table_ref = f"{project_id}.{dataset_id}.{table_id}"

def run_query(query):
    return list(client.query(query).result())

def check_qna_duplicates(target_date: str):
    print(f"\nproduct_qna ì¤‘ë³µ ì •í•©ì„± ì²´í¬: {target_date}")

    # ìˆ˜ì§‘ì¼ ê¸°ì¤€ ì „ì²´ ê±´ìˆ˜
    total = run_query(f"""
        SELECT COUNT(*) AS cnt
        FROM `{table_ref}`
        WHERE collected_dt = PARSE_DATE('%Y%m%d', '{target_date}')
    """)[0].cnt
    print(f"âœ… ìˆ˜ì§‘ì¼ ê¸°ì¤€ ì´ ê±´ìˆ˜: {total}ê±´")

    # qna_id ê¸°ì¤€ ì¤‘ë³µ ì²´í¬
    dup_result = run_query(f"""
        SELECT COUNT(*) AS dup_cnt FROM (
            SELECT qna_id, COUNT(*)
            FROM `{table_ref}`
            WHERE collected_dt = PARSE_DATE('%Y%m%d', '{target_date}')
            GROUP BY qna_id
            HAVING COUNT(*) > 1
        )
    """)[0].dup_cnt

    if dup_result > 0:
        print(f"âš ï¸ ì¤‘ë³µëœ qna_idê°€ {dup_result}ê±´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    else:
        print("âœ… qna_id ê¸°ì¤€ ì¤‘ë³µ ì—†ìŒ")

    # ë™ì¼ product_id + question_author + question_dt + question_text ì¡°í•© ì¤‘ë³µ ì²´í¬
    similar_result = run_query(f"""
        SELECT COUNT(*) AS dup_cnt FROM (
            SELECT product_id, question_author, question_dt, question_text, COUNT(*)
            FROM `{table_ref}`
            WHERE collected_dt = PARSE_DATE('%Y%m%d', '{target_date}')
            GROUP BY product_id, question_author, question_dt, question_text
            HAVING COUNT(*) > 1
        )
    """)[0].dup_cnt

    if similar_result > 0:
        print(f"âš ï¸ ë™ì¼ product_id + question_author + question_dt + question_text ì¤‘ë³µ {similar_result}ê±´ ì¡´ì¬")
    else:
        print("âœ… ì§ˆë¬¸ í…ìŠ¤íŠ¸ ê¸°ì¤€ ë…¼ë¦¬ì  ì¤‘ë³µ ì—†ìŒ")

    print("\nâœ… ì •í•©ì„± ì²´í¬ ì™„ë£Œ")

    # ë¸Œëœë“œ/ì œí’ˆë³„ Q&A ê°œìˆ˜ ë° ì§ˆë¬¸ì¼ì ë²”ìœ„ í™•ì¸
    print("\nğŸ“Š ë¸Œëœë“œ/ì œí’ˆë³„ Q&A ê±´ìˆ˜ ë° ì§ˆë¬¸ì¼ì ë¶„í¬:")

    records = run_query(f"""
        SELECT
        REGEXP_EXTRACT(qna_id, r'^([a-z0-9]+)') AS brand,
        product_id,
        COUNT(*) AS qna_count,
        MIN(question_dt) AS min_dt,
        MAX(question_dt) AS max_dt
        FROM `{table_ref}`
        WHERE collected_dt = PARSE_DATE('%Y%m%d', '{target_date}')
        GROUP BY brand, product_id
        ORDER BY brand, product_id
    """)

    for row in records:
        print(f"  - [{row.brand}] {row.product_id} : {row.qna_count}ê±´ ({row.min_dt} ~ {row.max_dt})")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--date", type=str, required=True, help="YYYYMMDD í˜•ì‹ ìˆ˜ì§‘ì¼ì")
    args = parser.parse_args()

    check_qna_duplicates(args.date)
