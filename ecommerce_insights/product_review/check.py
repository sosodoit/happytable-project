from google.cloud import bigquery
from google.oauth2 import service_account
from datetime import datetime
from pathlib import Path
import argparse

# ì¸ì¦ ë° BQ í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent.parent.parent
CREDENTIALS_FILE = str((BASE_DIR / "manggu-e08c8cf179d0.json").as_posix())
credentials = service_account.Credentials.from_service_account_file(CREDENTIALS_FILE)
client = bigquery.Client(credentials=credentials, project=credentials.project_id)

# í…Œì´ë¸” ì •ë³´
project_id = "manggu"
dataset_id = "ecommerce_insights"
table_id = "product_review"
table_ref = f"{project_id}.{dataset_id}.{table_id}"

def run_query(query):
    return list(client.query(query).result())

def check_review_duplicates(target_date: str):
    print(f"\nğŸ“‹ product_review ì •í•©ì„± ì²´í¬ ì‹œì‘: {target_date}")

    # 1. ìˆ˜ì§‘ì¼ ê¸°ì¤€ ì „ì²´ ê±´ìˆ˜
    total = run_query(f"""
        SELECT COUNT(*) AS cnt
        FROM `{table_ref}`
        WHERE collected_dt = PARSE_DATE('%Y%m%d', '{target_date}')
    """)[0].cnt
    print(f"âœ… ìˆ˜ì§‘ì¼ ê¸°ì¤€ ì´ ê±´ìˆ˜: {total}ê±´")

    # 2. review_id ê¸°ì¤€ ì¤‘ë³µ ì²´í¬
    dup_result = run_query(f"""
        SELECT COUNT(*) AS dup_cnt FROM (
            SELECT review_id, COUNT(*)
            FROM `{table_ref}`
            WHERE collected_dt = PARSE_DATE('%Y%m%d', '{target_date}')
            GROUP BY review_id
            HAVING COUNT(*) > 1
        )
    """)[0].dup_cnt

    if dup_result > 0:
        print(f"âš ï¸ ì¤‘ë³µëœ review_idê°€ {dup_result}ê±´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    else:
        print("âœ… review_id ê¸°ì¤€ ì¤‘ë³µ ì—†ìŒ")

    # 3. ë…¼ë¦¬ì  ì¤‘ë³µ ì²´í¬ (product_id + review_author + review_dt + review_text)
    similar_result = run_query(f"""
        SELECT COUNT(*) AS dup_cnt FROM (
            SELECT product_id, review_author, review_dt, review_text, COUNT(*)
            FROM `{table_ref}`
            WHERE collected_dt = PARSE_DATE('%Y%m%d', '{target_date}')
            GROUP BY product_id, review_author, review_dt, review_text
            HAVING COUNT(*) > 1
        )
    """)[0].dup_cnt

    if similar_result > 0:
        print(f"âš ï¸ ë™ì¼ product_id + review_author + review_dt + review_text ì¤‘ë³µ {similar_result}ê±´ ì¡´ì¬")
    else:
        print("âœ… ë¦¬ë·° í…ìŠ¤íŠ¸ ê¸°ì¤€ ë…¼ë¦¬ì  ì¤‘ë³µ ì—†ìŒ")

    # 4. ë¸Œëœë“œ/ì œí’ˆë³„ ë¦¬ë·° ìˆ˜ + ë‚ ì§œ ë²”ìœ„
    print("\nğŸ“Š ë¸Œëœë“œ/ì œí’ˆë³„ ë¦¬ë·° ê±´ìˆ˜ ë° ì‘ì„±ì¼ì ë¶„í¬:")

    records = run_query(f"""
        SELECT
            REGEXP_EXTRACT(review_id, r'^([a-z0-9]+)') AS brand,
            product_id,
            COUNT(*) AS review_count,
            MIN(review_dt) AS min_dt,
            MAX(review_dt) AS max_dt
        FROM `{table_ref}`
        WHERE collected_dt = PARSE_DATE('%Y%m%d', '{target_date}')
        GROUP BY brand, product_id
        ORDER BY brand, product_id
    """)

    for row in records:
        print(f"  - [{row.brand}] {row.product_id} : {row.review_count}ê±´ ({row.min_dt} ~ {row.max_dt})")

    print("\nâœ… ì •í•©ì„± ì²´í¬ ì™„ë£Œ")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--date", type=str, required=True, help="YYYYMMDD í˜•ì‹ ìˆ˜ì§‘ì¼ì")
    args = parser.parse_args()
    check_review_duplicates(args.date)
